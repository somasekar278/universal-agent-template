"""
{{ name }} - Simple Chatbot (CLI)
Generated by: Databricks Agent Toolkit

Quick start:
  python chatbot.py

Customize:
  - Edit system prompt below (line 29)
  - Change streaming mode in config.yaml
"""

from databricks_agent_toolkit.integrations import DatabricksLLM
import mlflow
import asyncio
import yaml
from pathlib import Path

# Load configuration
config_path = Path(__file__).parent / "config.yaml"
with open(config_path) as f:
    config = yaml.safe_load(f)

# Initialize LLM client
llm = DatabricksLLM(
    endpoint=config["model"]["endpoint"],
    auto_trace=True
)

async def chat(user_message: str):
    """Send message and get response (batch or streaming based on config)."""
    messages = [
        {"role": "system", "content": "You are a helpful AI assistant."},
        {"role": "user", "content": user_message}
    ]

    temperature = config["model"].get("temperature", 0.7)
    max_tokens = config["model"].get("max_tokens", 500)

    if config["model"].get("streaming", False):
        # Streaming: yield tokens as they arrive
        async for chunk in llm.stream(messages=messages, temperature=temperature, max_tokens=max_tokens):
            yield chunk
    else:
        # Batch: return complete response
        response = await llm.chat(messages=messages, temperature=temperature, max_tokens=max_tokens)
        yield response["content"]


async def main():
    """Simple CLI chat interface."""
    print(f"ü§ñ {{ name }}")
    print("Type 'quit' to exit\n")

    # Setup MLflow
    mlflow.set_tracking_uri("databricks")
    try:
        mlflow.set_experiment(config["mlflow"]["experiment"])
        print(f"üìä MLflow: {config['mlflow']['experiment']}\n")
    except Exception as e:
        print(f"‚ö†Ô∏è  MLflow: {e}\n")

    # Chat loop
    with mlflow.start_run(run_name="chat_session"):
        while True:
            user_input = input("You: ")
            if user_input.lower() == 'quit':
                break

            print("Bot: ", end="", flush=True)
            async for chunk in chat(user_input):
                print(chunk, end="", flush=True)
            print("\n")

    print("üëã Thanks for chatting!")


if __name__ == "__main__":
    asyncio.run(main())
