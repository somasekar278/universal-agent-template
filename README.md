# SOTA Agent - Universal Agent Workflow Template

**A generic, production-ready template for integrating AI agents into any application or data pipeline.**

ğŸ¯ **This is a TEMPLATE** - Use it to build agent workflows for any domain!

Originally designed for fraud detection, this architecture template applies to **any domain** requiring AI agent integration:
- ğŸ”’ Fraud Detection & Risk Analysis
- ğŸ’¬ Customer Support & Chatbots
- ğŸ“ Content Moderation & Policy Enforcement
- ğŸ¥ Healthcare & Diagnosis Support
- ğŸ” Data Quality & Anomaly Detection
- ğŸ“Š Analytics & Report Generation
- ğŸ¤– **Any Agent-Powered Workflow**

## ğŸš€ Quick Start

### One-Time Setup (30 seconds)

```bash
# Run setup script (Mac/Linux)
./setup.sh

# Or on Windows
setup.bat

# Or manually
pip install -r requirements.txt && pip install -e .
```

### Generate Projects (Anytime)

```bash
# Generate a complete project for your domain
python template_generator.py --domain "your_domain" --output ./your-project

cd your-project
python examples/example_usage.py  # Works immediately! âœ…
```

### Path 2: Integrate Into Existing Code (3 lines)

```python
from agents import AgentRouter

router = AgentRouter.from_yaml("config/agents.yaml")  # 1. Load
result = await router.route("your_agent", input_data)  # 2. Execute
# That's it! ğŸ‰
```

**ğŸ“– See [Getting Started Guide](GETTING_STARTED.md) for detailed 5-minute guide**

## Why Use This Template?

âœ¨ **Universal Design** - Works for any domain, not just fraud detection  
ğŸ”Œ **Plug-and-Play** - 3 lines to integrate into existing pipelines  
âš™ï¸ **Configuration-Driven** - Enable/disable agents via YAML, zero code changes  
ğŸ¯ **SLA-Aware** - Control inline vs async execution based on your requirements  
ğŸ—ï¸ **Production-Ready** - Battle-tested patterns, not toy examples  
ğŸ“¦ **Complete Stack** - Includes telemetry, evaluation, optimization, deployment  
ğŸš€ **Template Generator** - Scaffold new projects in seconds  

## Architecture Overview

This project implements a **domain-agnostic, plug-and-play agent framework** that integrates into existing data pipelines with minimal code changes. The architecture leverages:

- **Ephemeral Agents**: Task-specific narrative agents that spin up on-demand
- **Hot LLM Pools**: Always-on GPU endpoints via Databricks Model Serving
- **Prompt Optimization**: DSPy for task prompts, TextGrad for system prompts
- **Memory & Context**: Lakebase for conversation history and embeddings
- **MCP Tool Calling**: Standardized tool interfaces via Model Context Protocol
- **Observability**: OTEL â†’ Zerobus â†’ Delta Lake telemetry pipeline
- **Evaluation**: MLflow custom scorers and continuous feedback loops

## Key Features

ğŸ”Œ **Plug-and-Play Integration** - Add to existing pipelines with 3 lines of code  
âš™ï¸ **Configuration-Driven** - Enable/disable agents via YAML, no code changes  
ğŸ¯ **SLA-Aware Execution** - Control inline vs offline based on requirements  
ğŸ”’ **Type-Safe** - Pydantic schemas validate all data at runtime  
ğŸŒ **ASGI Support** - FastAPI endpoints, SSE streaming, async HTTP  
ğŸ”„ **Agent-to-Agent (A2A)** - Event-driven agent communication via NATS/Redis (optional)  
âœ¨ **Domain-Agnostic** - Works for fraud, risk, support, compliance, or any use case  
ğŸ“ˆ **Prompt Optimization** - DSPy for task prompts, TextGrad for system prompts  
ğŸ“Š **Comprehensive Telemetry** - All events streamed to Delta Lake via Zerobus  
ğŸ§  **Memory Management** - Lakebase for vector embeddings and conversation history  
ğŸ”§ **MCP Tool Integration** - Standardized external tool calling  
ğŸ“‰ **MLflow Tracking** - Experiment tracking, evaluation, and model registry  
ğŸ›ï¸ **Unity Catalog** - Centralized prompt and model versioning  
ğŸ¢ **Multi-Tenant Ready** - Schema adapters handle any customer format  

## Project Structure

```
.
â”œâ”€â”€ agents/                     # ğŸ¤– Agent framework (CORE)
â”‚   â”œâ”€â”€ base.py                #    - Base agent interfaces
â”‚   â”œâ”€â”€ config.py              #    - Configuration loader
â”‚   â”œâ”€â”€ registry.py            #    - Agent registry + router
â”‚   â””â”€â”€ execution/             #    - Pluggable execution backends
â”œâ”€â”€ shared/                    # ğŸ“¦ Shared libraries
â”‚   â”œâ”€â”€ schemas/               #    - Pydantic data models (type-safe)
â”‚   â””â”€â”€ adapters/              #    - Schema adaptation framework
â”œâ”€â”€ config/                    # âš™ï¸  Configuration (plug-and-play)
â”‚   â”œâ”€â”€ agents/                #    - Agent configurations (YAML)
â”‚   â””â”€â”€ adapters/              #    - Customer schema adapters
â”œâ”€â”€ services/                  # ğŸš€ Deployable services
â”œâ”€â”€ optimization/              # ğŸ“ Prompt optimization (DSPy/TextGrad)
â”œâ”€â”€ memory/                    # ğŸ§  Lakebase integration
â”œâ”€â”€ orchestration/             # ğŸ”„ Databricks Workflows + LangGraph
â”œâ”€â”€ mcp-servers/               # ğŸ”§ Model Context Protocol tools
â”œâ”€â”€ evaluation/                # ğŸ“Š MLflow scorers and metrics
â”œâ”€â”€ telemetry/                 # ğŸ“ˆ OTEL â†’ Zerobus â†’ Delta
â”œâ”€â”€ uc-registry/               # ğŸ—ƒï¸  Unity Catalog integration
â”œâ”€â”€ data/                      # ğŸ“Š Synthetic testbed
â”œâ”€â”€ infrastructure/            # ğŸ—ï¸  Deployment configs (DABS)
â”œâ”€â”€ experiments/               # ğŸ”¬ Notebooks + MLflow tracking
â”œâ”€â”€ tests/                     # ğŸ§ª Unit, integration, load tests
â””â”€â”€ docs/                      # ğŸ“– Documentation
```

**See [Project Structure](docs/PROJECT_STRUCTURE.md) for detailed breakdown with key concepts.**

## Data Schemas

All data structures are defined using Pydantic models in `shared/schemas/`:

- **transactions.py** - Transaction records and payment data
- **fraud_signals.py** - Velocity, amount, location, device signals
- **contexts.py** - Merchant and customer profiles
- **agent_io.py** - Agent inputs, outputs, tool calls (MCP-ready)
- **evaluation.py** - Evaluation records and scorer metrics
- **telemetry.py** - OTEL traces for Zerobus ingestion

See `shared/schemas/README.md` for detailed documentation.

## Quick Start (Plug-and-Play)

Add agents to your existing pipeline in 3 lines:

```python
from agents import AgentRouter
from shared.schemas import AgentInput

# 1. Load agents from config (one line!)
router = AgentRouter.from_yaml("config/agents.yaml")

# 2. Convert your data to AgentInput (Pydantic validates!)
agent_input = AgentInput(
    request_id=record.id,
    data=YourDomainData(**record.dict()),  # Your domain-specific data
    # ... your contexts
)

# 3. Route to agent (inline or offline based on config!)
result = await router.route("your_agent", agent_input)

# That's it! Agent runs according to your config.
# No code changes to enable/disable or switch execution modes.
```

**Configuration controls everything:**

```yaml
# config/agents.yaml
agents:
  your_agent:
    class: "your_package.YourAgent"
    execution_mode: "offline"  # or "inline" if SLA allows
    enabled: true              # Change to false to disable
    timeout: 30
```

**Works for any domain:** Fraud detection, risk analysis, customer support, compliance, content moderation, etc.

See [Configuration System](docs/CONFIGURATION_SYSTEM.md) for details.

---

## Getting Started

### Prerequisites

- Python 3.9+
- Databricks workspace with:
  - Model Serving endpoint
  - Unity Catalog
  - Lakebase access
- Zerobus server endpoint (for telemetry)

### Installation

```bash
# Clone the repository
git clone <repo-url>
cd "SOTA Agent"

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or install in development mode
pip install -e ".[dev]"
```

### Configuration

```bash
# Copy example config
cp .env.example .env

# Edit .env with your Databricks credentials
# - DATABRICKS_HOST
# - DATABRICKS_TOKEN
# - MODEL_SERVING_ENDPOINT
# - UNITY_CATALOG_NAME
# - ZEROBUS_ENDPOINT
```

## Databricks Stack

| Component | Technology |
|-----------|-----------|
| LLM Inference | Databricks Model Serving |
| Orchestration | LangGraph + Databricks Workflows |
| Tracing & Evaluation | Databricks MLflow |
| Memory/Vector Store | Lakebase |
| Telemetry Sink | Zerobus â†’ Delta Lake |
| Prompt Registry | Unity Catalog |
| Dashboards | Databricks SQL |
| Compute | Databricks Clusters / Serverless |

## Development

### Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test suite
pytest tests/unit/
pytest tests/integration/
```

### Code Quality

```bash
# Format code
black .

# Lint
ruff check .

# Type check
mypy .
```

## Architecture Flows

### Realtime Path (Low-latency)
Transaction â†’ Event Collector â†’ Ephemeral Narrative Agent â†’ MCP Tool Calls â†’ LLM Pool â†’ Risk Narrative â†’ Dashboard/Alerts

### Async Path (Optimization)
MLflow Scorers â†’ Evaluate High-Risk Txns â†’ Log Metrics â†’ DSPy/TextGrad Optimization â†’ Update Prompts in UC â†’ Deploy to Agents

## MCP Integration

All tool calls use Model Context Protocol for standardization:

```python
# Tool call schema (MCP-ready)
tool_call = ToolCall(
    tool_id="call_123",
    tool_name="merchant_context",
    tool_server="uc-query-server",
    arguments={"merchant_id": "mch_001"}
)

# Tool result
tool_result = ToolResult(
    tool_call_id="call_123",
    success=True,
    result=merchant_data,
    latency_ms=45.2
)
```

See `mcp-servers/` for tool implementations.

## Telemetry

All events flow through OTEL â†’ Zerobus â†’ Delta Lake:

- Agent start/complete/error
- MCP tool calls
- LLM requests/responses
- Stream chunks
- Evaluation results

Query telemetry in Unity Catalog:

```sql
SELECT * FROM main.telemetry.agent_traces
WHERE transaction_id = 'txn_123'
ORDER BY timestamp DESC;
```

## Prompt Optimization

### DSPy (Task Prompts)
```python
# Optimize reasoning pipeline
from optimization.dspy import MIPROOptimizer

optimizer = MIPROOptimizer(training_data)
optimized_prompt = optimizer.optimize(baseline_prompt)
```

### TextGrad (System Prompts)
```python
# Optimize system prompt with guardrails
from optimization.textgrad import SystemPromptOptimizer

optimizer = SystemPromptOptimizer(feedback_data)
optimized_system = optimizer.optimize(system_prompt)
```

## Synthetic Data

Generate idempotent test data:

```bash
# Generate synthetic transactions
python -m data.synthetic.generate --seed 42 --count 5000

# Output: data/synthetic/raw/transactions.parquet
```

## Contributing

1. Create a feature branch
2. Make changes with tests
3. Run linters and tests
4. Submit pull request

## License

MIT

## Documentation

### ğŸ¯ Start Here
- **[Getting Started](GETTING_STARTED.md)** â­ - 5-minute quick start guide
- **[Template Guide](docs/TEMPLATE_GUIDE.md)** â­ - Comprehensive guide for any domain
- **[Cross-Domain Examples](docs/CROSS_DOMAIN_EXAMPLES.md)** â­ - 8 real-world examples
- **[Documentation Index](docs/README.md)** - Complete documentation map

### ğŸ“š Core Documentation
- **[Project Structure](docs/PROJECT_STRUCTURE.md)** - Code organization and key concepts
- **[Configuration System](docs/CONFIGURATION_SYSTEM.md)** - YAML-based configuration
- **[Schema Documentation](docs/schemas/)** - Data schemas and adaptation
- **[Use Cases](docs/USE_CASES.md)** - Advanced usage patterns

### ğŸ› ï¸ Tools
- **Template Generator** - `python template_generator.py --help`
- **Example Integrations** - `examples/plug_and_play_integration.py`

## Contact

For questions, see `docs/` or contact the team.

