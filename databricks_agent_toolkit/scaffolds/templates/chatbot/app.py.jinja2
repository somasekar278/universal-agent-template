"""
{{ name }} - Chatbot Web App
Generated by: Databricks Agent Toolkit v0.1.0

A simple web-based chatbot powered by Databricks Model Serving.
"""

from flask import Flask, request, jsonify, render_template_string, Response, stream_with_context
from databricks_agent_toolkit.integrations import DatabricksLLM
import mlflow
import os
import yaml
import json
from pathlib import Path

# Load configuration
config_path = Path(__file__).parent / "config.yaml"
with open(config_path) as f:
    config = yaml.safe_load(f)

# Initialize Flask app
app = Flask(__name__)
PORT = int(os.getenv('DATABRICKS_APP_PORT', 8000))

# Initialize LLM client (uses REST API, works in Databricks Apps)
llm = DatabricksLLM(
    endpoint=config.get("model", {}).get("endpoint", "{{ model }}"),
    auto_trace=config.get("mlflow", {}).get("auto_trace", True)
)

# Set up MLflow tracking
mlflow.set_tracking_uri("databricks")
experiment = config.get("mlflow", {}).get("experiment", "/Shared/{{ name }}")
try:
    mlflow.set_experiment(experiment)
    print(f"üìä MLflow: {experiment}")
except Exception as e:
    print(f"‚ö†Ô∏è  MLflow setup: {e}")

# HTML template for chat UI
CHAT_HTML = '''
<!DOCTYPE html>
<html>
<head>
    <title>{{ name }}</title>
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            max-width: 900px; 
            margin: 0 auto; 
            padding: 20px;
            background: #f5f5f5;
        }
        h1 { 
            color: #FF3621; 
            margin-bottom: 5px;
        }
        .subtitle {
            color: #666;
            margin-bottom: 20px;
        }
        #chat-container {
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        #chat-box { 
            height: 500px; 
            overflow-y: auto; 
            padding: 20px; 
            background: white;
        }
        .message { 
            margin: 15px 0; 
            padding: 12px 16px; 
            border-radius: 8px;
            max-width: 80%;
            line-height: 1.5;
        }
        .user { 
            background: #e3f2fd; 
            margin-left: auto;
            text-align: right;
        }
        .assistant { 
            background: #fff3e0;
        }
        #input-container {
            display: flex;
            gap: 10px;
            padding: 20px;
            background: #f9f9f9;
            border-top: 1px solid #e0e0e0;
        }
        #input-box { 
            flex: 1;
            padding: 12px 16px;
            border: 1px solid #ddd;
            border-radius: 6px;
            font-size: 14px;
        }
        #send-btn { 
            padding: 12px 24px;
            background: #FF3621;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-weight: 500;
            transition: background 0.2s;
        }
        #send-btn:hover { 
            background: #d32f2f;
        }
        #send-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .loading {
            color: #999;
            font-style: italic;
        }
    </style>
</head>
<body>
    <h1>ü§ñ {{ name }}</h1>
    <p class="subtitle">Powered by <strong>{{ model }}</strong></p>
    
    <div id="chat-container">
        <div id="chat-box"></div>
        <div id="input-container">
            <input type="text" id="input-box" placeholder="Type your message..." onkeypress="if(event.key==='Enter' && !event.shiftKey) sendMessage()">
            <button id="send-btn" onclick="sendMessage()">Send</button>
        </div>
    </div>
    
    <script>
        const STREAMING_ENABLED = {{ 'true' if config.get("model", {}).get("streaming", False) else 'false' }};
        
        function sendMessage() {
            const input = document.getElementById('input-box');
            const sendBtn = document.getElementById('send-btn');
            const message = input.value.trim();
            
            if (!message) return;
            
            // Show user message
            addMessage('user', message);
            input.value = '';
            sendBtn.disabled = true;
            
            if (STREAMING_ENABLED) {
                // Streaming mode with EventSource
                const assistantMsgId = addMessage('assistant', '');
                
                fetch('/api/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: message})
                })
                .then(response => {
                    const reader = response.body.getReader();
                    const decoder = new TextDecoder();
                    let buffer = '';
                    let fullResponse = '';
                    
                    function processStream() {
                        reader.read().then(({done, value}) => {
                            if (done) {
                                sendBtn.disabled = false;
                                return;
                            }
                            
                            buffer += decoder.decode(value, {stream: true});
                            const lines = buffer.split('\n\n');
                            buffer = lines.pop();
                            
                            for (const line of lines) {
                                if (line.startsWith('data: ')) {
                                    const data = JSON.parse(line.substring(6));
                                    if (data.chunk) {
                                        fullResponse += data.chunk;
                                        updateMessage(assistantMsgId, fullResponse);
                                    } else if (data.done) {
                                        sendBtn.disabled = false;
                                    } else if (data.error) {
                                        updateMessage(assistantMsgId, 'Error: ' + data.error);
                                        sendBtn.disabled = false;
                                    }
                                }
                            }
                            
                            processStream();
                        });
                    }
                    
                    processStream();
                })
                .catch(err => {
                    updateMessage(assistantMsgId, 'Error: ' + err);
                    sendBtn.disabled = false;
                });
            } else {
                // Non-streaming mode
                const loadingId = addMessage('assistant', 'Thinking...', 'loading');
                
                fetch('/api/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: message})
                })
                .then(r => r.json())
                .then(data => {
                    document.getElementById(loadingId).remove();
                    
                    if (data.error) {
                        addMessage('assistant', 'Error: ' + data.error);
                    } else {
                        addMessage('assistant', data.response);
                    }
                    sendBtn.disabled = false;
                })
                .catch(err => {
                    document.getElementById(loadingId).remove();
                    addMessage('assistant', 'Error: ' + err);
                    sendBtn.disabled = false;
                });
            }
        }
        
        function addMessage(role, content, extraClass = '') {
            const chatBox = document.getElementById('chat-box');
            const div = document.createElement('div');
            const id = 'msg-' + Date.now();
            div.id = id;
            div.className = 'message ' + role + (extraClass ? ' ' + extraClass : '');
            div.textContent = content;
            chatBox.appendChild(div);
            chatBox.scrollTop = chatBox.scrollHeight;
            return id;
        }
        
        function updateMessage(id, content) {
            const msg = document.getElementById(id);
            if (msg) {
                msg.textContent = content;
                const chatBox = document.getElementById('chat-box');
                chatBox.scrollTop = chatBox.scrollHeight;
            }
        }
    </script>
</body>
</html>
'''

@app.route('/')
def home():
    """Main chat interface"""
    return render_template_string(
        CHAT_HTML,
        name=config.get("agent_name", "{{ name }}"),
        model=config.get("model", {}).get("endpoint", "{{ model }}")
    )

@app.route('/health')
def health():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "model": config.get("model", {}).get("endpoint", "{{ model }}"),
        "port": PORT
    })

@app.route('/api/chat', methods=['POST'])
@mlflow.trace(name="chatbot", span_type="CHAIN")
def chat():
    """Chat API endpoint with MLflow tracing"""
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        
        if not user_message:
            return jsonify({"error": "No message provided"}), 400
        
        # Check if streaming is enabled
        streaming_enabled = config.get("model", {}).get("streaming", False)
        
        messages = [
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": user_message}
        ]
        
        if streaming_enabled:
            # Streaming mode with Server-Sent Events
            def generate():
                import asyncio
                try:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    stream = loop.run_until_complete(llm.stream(
                        messages=messages,
                        temperature=config.get("model", {}).get("temperature", 0.7),
                        max_tokens=config.get("model", {}).get("max_tokens", 500)
                    ))
                    
                    for chunk in stream:
                        if chunk and "content" in chunk:
                            yield f"data: {json.dumps({'chunk': chunk['content']})}\n\n"
                    
                    yield f"data: {json.dumps({'done': True})}\n\n"
                    loop.close()
                except Exception as e:
                    yield f"data: {json.dumps({'error': str(e)})}\n\n"
            
            return Response(stream_with_context(generate()), mimetype='text/event-stream')
        else:
            # Non-streaming mode
            import asyncio
            response = asyncio.run(llm.chat(
                messages=messages,
                temperature=config.get("model", {}).get("temperature", 0.7),
                max_tokens=config.get("model", {}).get("max_tokens", 500)
            ))
            return jsonify({"response": response["content"]})
        
    except Exception as e:
        print(f"‚ùå Error: {e}", flush=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print(f"üöÄ Starting {{ name }} on port {PORT}", flush=True)
    app.run(host='0.0.0.0', port=PORT, debug=False)

