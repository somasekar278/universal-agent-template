# MCP Server Deployment Configuration
#
# This file controls how MCP servers are deployed and accessed.
# Choose the deployment mode based on your scale and requirements.

deployment_mode: embedded  # Options: "embedded", "separate", "external"

# ============================================================================
# MODE 1: EMBEDDED (Default - Simplest)
# ============================================================================
# Both MCP servers run inside the same container as the agent app.
# Use for: 1-5 agents, < 100 req/min, development
# Resources: 4 CPU, 16GB memory recommended

embedded:
  enabled: true

  mlflow_mcp:
    enabled: true
    port: 5000
    host: "0.0.0.0"
    startup_timeout_seconds: 10
    healthcheck_endpoint: "http://localhost:5000/health"
    command: ["mlflow", "server", "mcp", "--host", "0.0.0.0", "--port", "5000"]
    env:
      MLFLOW_TRACKING_URI: "databricks"
      # DATABRICKS_HOST and DATABRICKS_TOKEN inherited from parent process

  databricks_mcp:
    enabled: true
    port: 6000
    host: "0.0.0.0"
    startup_timeout_seconds: 10
    healthcheck_endpoint: "http://localhost:6000/health"
    command: ["python", "-m", "databricks_mcp.server", "--host", "0.0.0.0", "--port", "6000"]
    # DATABRICKS_HOST, DATABRICKS_TOKEN, AGENT_FRAMEWORK_PATH inherited

  resource_limits:
    max_cpu_percent: 80  # Alert if CPU > 80%
    max_memory_percent: 85  # Alert if Memory > 85%
    monitoring_interval_seconds: 60

# ============================================================================
# MODE 2: SEPARATE (Sidecar/Service)
# ============================================================================
# MCP servers run as separate services (different containers/apps).
# Use for: 5-20 agents, 100-500 req/min, multiple teams
# Resources: 4 CPU (agents) + 2 CPU (MCP) = 6 CPU total

separate:
  enabled: false

  mlflow_mcp:
    endpoint: "http://mcp-servers:5000"  # Internal DNS name or IP
    timeout_seconds: 30
    retry_attempts: 3
    healthcheck_enabled: true

  databricks_mcp:
    endpoint: "http://mcp-servers:6000"  # Internal DNS name or IP
    timeout_seconds: 30
    retry_attempts: 3
    healthcheck_enabled: true

# ============================================================================
# MODE 3: EXTERNAL (Existing/Managed MCP Servers)
# ============================================================================
# Use EXISTING MCP servers that are already deployed/managed:
# - Databricks-managed MCP servers (e.g., native MLflow MCP)
# - Public MCP servers (e.g., GitHub MCP, Slack MCP)
# - Third-party MCP services
# - Your own separately deployed MCP servers
#
# Use for: Enterprise scale, using managed services, public tools
# Resources: No local resources needed - connects to external endpoints

external:
  enabled: false

  # Native MLflow MCP (built into Databricks MLflow 3.5.1+)
  mlflow_mcp:
    endpoint: "${MLFLOW_MCP_ENDPOINT}"  # e.g., "https://your-workspace.cloud.databricks.com/mlflow/mcp"
    timeout_seconds: 30
    retry_attempts: 3
    healthcheck_enabled: true
    auth:
      type: "bearer_token"  # Options: "none", "bearer_token", "api_key"
      token: "${DATABRICKS_TOKEN}"  # Use Databricks token

  # Your custom Databricks Agent MCP (if deployed separately)
  databricks_mcp:
    endpoint: "${DATABRICKS_MCP_ENDPOINT}"  # e.g., "https://mcp.yourcompany.com/agent-tools"
    timeout_seconds: 30
    retry_attempts: 3
    healthcheck_enabled: true
    auth:
      type: "bearer_token"
      token: "${DATABRICKS_MCP_AUTH_TOKEN}"

  # =========================================================================
  # DATABRICKS MANAGED MCP SERVERS (Native)
  # =========================================================================
  # Databricks provides 4 ready-to-use managed MCP servers (Beta)
  # See: https://docs.databricks.com/aws/en/generative-ai/mcp/managed-mcp

  # 1. Unity Catalog Functions MCP
  #    Run predefined SQL queries via UC functions
  # uc_functions_mcp:
  #   endpoint: "https://${DATABRICKS_HOST}/api/2.0/mcp/functions/${CATALOG}/${SCHEMA}"
  #   timeout_seconds: 30
  #   retry_attempts: 3
  #   auth:
  #     type: "bearer_token"
  #     token: "${DATABRICKS_TOKEN}"
  #   examples:
  #     # Example: Access billing functions
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/functions/prod/billing"
  #     # Example: Access customer support functions
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/functions/prod/customer_support"

  # 2. Vector Search MCP
  #    Query Vector Search indexes (only indexes with Databricks managed embeddings)
  # vector_search_mcp:
  #   endpoint: "https://${DATABRICKS_HOST}/api/2.0/mcp/vector-search/${CATALOG}/${SCHEMA}"
  #   timeout_seconds: 30
  #   retry_attempts: 3
  #   auth:
  #     type: "bearer_token"
  #     token: "${DATABRICKS_TOKEN}"
  #   examples:
  #     # Example: Search support tickets and docs
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/vector-search/prod/customer_support"
  #     # Example: Search product documentation
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/vector-search/prod/product_docs"

  # 3. Genie Space MCP
  #    Query Genie spaces to analyze structured data using natural language
  #    Note: For external assistants (Claude, ChatGPT) for read-only ops
  # genie_space_mcp:
  #   endpoint: "https://${DATABRICKS_HOST}/api/2.0/mcp/genie/${GENIE_SPACE_ID}"
  #   timeout_seconds: 60  # Genie queries can be slower
  #   retry_attempts: 2
  #   auth:
  #     type: "bearer_token"
  #     token: "${DATABRICKS_TOKEN}"
  #   examples:
  #     # Example: Query billing data
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/genie/01234567-89ab-cdef-0123-456789abcdef"

  # 4. DBSQL MCP
  #    Run AI-generated SQL (for AI coding tools like Cursor, Claude Code)
  #    Note: For read-only data retrieval, use Genie instead
  # dbsql_mcp:
  #   endpoint: "https://${DATABRICKS_HOST}/api/2.0/mcp/sql"
  #   timeout_seconds: 60
  #   retry_attempts: 2
  #   auth:
  #     type: "bearer_token"
  #     token: "${DATABRICKS_TOKEN}"
  #   examples:
  #     # Used for authoring data pipelines with AI coding assistants
  #     # - "https://your-workspace.cloud.databricks.com/api/2.0/mcp/sql"

  # =========================================================================
  # EXAMPLE: Multi-MCP Customer Support Agent
  # =========================================================================
  # Real-world scenario: Customer support agent with multiple MCP servers
  #
  # customer_support_agent:
  #   vector_search: "https://<host>/api/2.0/mcp/vector-search/prod/customer_support"
  #   genie_billing: "https://<host>/api/2.0/mcp/genie/{billing_space_id}"
  #   uc_functions: "https://<host>/api/2.0/mcp/functions/prod/billing"
  #
  # This gives your agent:
  #   - Unstructured data (support tickets via Vector Search)
  #   - Structured data (billing tables via Genie)
  #   - Custom business logic (account lookups via UC Functions)

  # =========================================================================
  # PUBLIC/THIRD-PARTY MCP SERVERS
  # =========================================================================

  # GitHub MCP (if available as managed service)
  # github_mcp:
  #   endpoint: "https://api.github.com/mcp"
  #   timeout_seconds: 30
  #   auth:
  #     type: "bearer_token"
  #     token: "${GITHUB_TOKEN}"

  # Slack MCP (if available as managed service)
  # slack_mcp:
  #   endpoint: "https://mcp.slack.com/v1"
  #   timeout_seconds: 30
  #   auth:
  #     type: "bearer_token"
  #     token: "${SLACK_MCP_TOKEN}"

  # Custom Enterprise MCP Server
  # enterprise_tools_mcp:
  #   endpoint: "https://mcp.enterprise.com/tools"
  #   timeout_seconds: 60
  #   auth:
  #     type: "api_key"
  #     api_key: "${ENTERPRISE_MCP_KEY}"
  #     header_name: "X-API-Key"  # Optional: custom auth header name

# ============================================================================
# Common Settings (All Modes)
# ============================================================================

connection:
  max_connections: 100
  connection_timeout_seconds: 10
  read_timeout_seconds: 30

  # Connection pooling
  pool_size: 10
  pool_max_overflow: 20

monitoring:
  enabled: true
  metrics:
    - mcp_request_count
    - mcp_request_duration_seconds
    - mcp_error_count
    - mcp_connection_errors

  health_check_interval_seconds: 60

  # Alert when MCP servers are unhealthy
  alerts:
    - name: mcp_server_down
      condition: "health_check_failed"
      severity: critical
      action: "restart_or_notify"

    - name: high_latency
      condition: "p95_latency > 5s"
      severity: warning
      action: "log"

# ============================================================================
# Fallback & Resilience
# ============================================================================

resilience:
  # If MCP servers are unavailable, should agents fail or continue?
  fallback_mode: "continue_without_mcp"  # Options: "fail", "continue_without_mcp"

  # Circuit breaker
  circuit_breaker:
    enabled: true
    failure_threshold: 5  # Open circuit after 5 failures
    timeout_seconds: 60  # Try again after 60s
    success_threshold: 2  # Close circuit after 2 successes

  # Retry policy
  retry:
    enabled: true
    max_attempts: 3
    backoff_multiplier: 2  # Exponential backoff: 1s, 2s, 4s
    max_backoff_seconds: 10

# ============================================================================
# Development Overrides
# ============================================================================

# Override for local development
development:
  deployment_mode: embedded
  embedded:
    mlflow_mcp:
      port: 5000
      host: "localhost"
    databricks_mcp:
      port: 6000
      host: "localhost"

# Override for testing
testing:
  deployment_mode: external
  external:
    mlflow_mcp:
      endpoint: "http://localhost:5000"
    databricks_mcp:
      endpoint: "http://localhost:6000"
