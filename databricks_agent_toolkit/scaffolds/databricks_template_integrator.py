"""
Databricks App Template Integrator

Integrates official Databricks app templates (Streamlit, Gradio, Dash) with agent generation.
Avoids custom frontend generation - uses battle-tested Databricks templates.
"""

import shutil
from pathlib import Path
from typing import Any, Dict


class DatabricksTemplateIntegrator:
    """Integrate official Databricks app templates."""

    # Map UI framework to template directory
    TEMPLATE_MAP = {
        "streamlit": "e2e-chatbot-app",
        "gradio": "gradio-chatbot-app",
        "dash": "dash-chatbot-app",
    }

    def __init__(self):
        # Try local dev path first
        self.templates_root = Path(__file__).parent.parent.parent / "databricks-app-templates-research"

        # If not found (installed package), use user's home directory cache
        if not self.templates_root.exists():
            self.templates_root = Path.home() / ".databricks-agent-toolkit" / "templates"

            # Auto-clone if not exists
            if not self.templates_root.exists():
                print("ðŸ“¥ Downloading Databricks app templates (first time only)...")
                self._clone_templates()

    def _clone_templates(self) -> None:
        """Clone Databricks templates repo to local cache."""
        import subprocess

        cache_dir = Path.home() / ".databricks-agent-toolkit"
        cache_dir.mkdir(parents=True, exist_ok=True)

        try:
            subprocess.run(
                [
                    "git",
                    "clone",
                    "--depth",
                    "1",
                    "https://github.com/databricks/app-templates.git",
                    str(self.templates_root),
                ],
                check=True,
                capture_output=True,
            )
            print(f"âœ… Templates downloaded to: {self.templates_root}")
        except subprocess.CalledProcessError as e:
            raise RuntimeError(
                f"Failed to clone templates: {e.stderr.decode()}\n"
                f"Please clone manually: git clone https://github.com/databricks/databricks-app-templates.git {self.templates_root}"
            )

    def get_template_path(self, ui_framework: str) -> Path:
        """Get the template directory path for a UI framework."""
        template_name = self.TEMPLATE_MAP.get(ui_framework)
        if not template_name:
            raise ValueError(f"Unsupported UI framework: {ui_framework}. Choose from: {list(self.TEMPLATE_MAP.keys())}")

        template_path = self.templates_root / template_name
        if not template_path.exists():
            raise FileNotFoundError(f"Template not found: {template_path}")

        return template_path

    def copy_template(self, ui_framework: str, output_dir: Path) -> None:
        """Copy the official Databricks template to output directory."""
        template_path = self.get_template_path(ui_framework)

        print(f"ðŸ“¦ Using official Databricks template: {template_path.name}")

        # Warn about streaming support
        if ui_framework in ["gradio", "dash"]:
            print(f"âš ï¸  Note: {ui_framework.capitalize()} template does not support streaming responses")
            print(f"   Responses will be batch-only. For streaming, use --ui streamlit")

        # Copy entire template directory
        shutil.copytree(template_path, output_dir, dirs_exist_ok=True)

        # Remove .git if exists (don't want nested git repos)
        git_dir = output_dir / ".git"
        if git_dir.exists():
            shutil.rmtree(git_dir)

        # Add databricks.yml if not present (for Asset Bundle deployment)
        if not (output_dir / "databricks.yml").exists():
            self._create_databricks_yml(output_dir)

    def _create_databricks_yml(self, output_dir: Path) -> None:
        """Create databricks.yml for Asset Bundle deployment."""
        app_name = output_dir.name
        databricks_yml = f"""bundle:
  name: {app_name}

resources:
  apps:
    {app_name}:
      name: {app_name}
      description: "Generated by Databricks Agent Toolkit"
      source_code_path: .

targets:
  dev:
    mode: development
    default: true
    workspace:
      root_path: /Workspace/${{workspace.current_user.userName}}/.bundle/${{bundle.name}}/${{bundle.target}}
"""
        (output_dir / "databricks.yml").write_text(databricks_yml)
        print("âœ… Added databricks.yml for Asset Bundle deployment")

    def customize_template(self, output_dir: Path, options: Dict[str, Any]) -> None:
        """Customize the template with user options (model endpoint, etc)."""
        ui = options.get("ui", "streamlit")
        model = options.get("model", "databricks-claude-sonnet-4")
        level = options.get("level", "chatbot")

        print(f"ðŸ”§ Customizing {ui} template for {level}...")

        # 1. Update app.yaml with model endpoint
        self._update_app_yaml(output_dir, model)

        # 2. Strip L2 features if generating L1
        if level == "chatbot":
            self._strip_memory_features(output_dir, ui)

        # 3. Update README
        self._update_readme(output_dir, ui, model, level)

        print(f"âœ… Template customized for model: {model}")

    def _update_app_yaml(self, output_dir: Path, model: str) -> None:
        """Update app.yaml with the correct model endpoint."""
        app_yaml_path = output_dir / "app.yaml"
        if not app_yaml_path.exists():
            return

        content = app_yaml_path.read_text()

        # Replace SERVING_ENDPOINT configuration
        if 'valueFrom: "serving-endpoint"' in content:
            # Replace resource reference with direct value
            content = content.replace('valueFrom: "serving-endpoint"', f'value: "{model}"')
            app_yaml_path.write_text(content)
            print(f"âœ… Configured SERVING_ENDPOINT: {model}")
        elif "SERVING_ENDPOINT" in content:
            print(f"âš ï¸  SERVING_ENDPOINT found but in unexpected format")
            print(f"   Manually set to: {model}")

    def _strip_memory_features(self, output_dir: Path, ui: str) -> None:
        """Remove memory-related UI components for L1 chatbots."""
        # TODO: Implement UI-specific stripping
        # For Streamlit: Remove session history sidebar, clear history button
        # For Dash: Remove conversation history panel
        # For Gradio: Remove chat history component
        print("âš ï¸  Memory features not stripped yet (template may show extra UI)")
        print("   L1 apps will work but may have unused UI elements")

    def _update_readme(self, output_dir: Path, ui: str, model: str, level: str) -> None:
        """Update or create README with generation info."""
        readme_path = output_dir / "README.md"
        readme_content = f"""# {output_dir.name}

Generated using **Databricks Agent Toolkit** with official {ui.capitalize()} template.

**Level**: {level.upper()}
**Model**: `{model}`
**UI Framework**: {ui.capitalize()}

## Quick Start

1. **Deploy to Databricks**:
   ```bash
   databricks bundle deploy
   databricks bundle run
   ```

2. **View in Databricks Apps UI**

3. **Configure Model Endpoint**:
   - Update `app.yaml` to set `SERVING_ENDPOINT` to your model endpoint name
   - Or use Databricks Apps resources to auto-configure

## Architecture

- **UI**: Official Databricks {ui.capitalize()} template
- **Backend**: Databricks Model Serving endpoint
- **Features**: {'Basic chat (no memory)' if level == 'chatbot' else 'Chat with memory & RAG'}

"""

        # Append original README if exists
        if readme_path.exists():
            original = readme_path.read_text()
            readme_content += f"\n---\n\n## Original Template README\n\n{original}"

        readme_path.write_text(readme_content)

    def integrate_memory(self, output_dir: Path, memory_config: Dict[str, Any]) -> None:
        """Add memory capabilities to the template (for L2+)."""
        ui = memory_config.get("ui", "streamlit")

        print(f"ðŸ’¾ Integrating memory for {ui}...")

        # Only Streamlit is supported for L2
        if ui != "streamlit":
            print(f"âš ï¸  Memory not supported for {ui} - only Streamlit has memory support")
            return

        # 1. Copy memory_manager.py from templates
        self._copy_memory_manager(output_dir)

        # 2. Update app.py for memory persistence
        self._inject_memory_into_streamlit(output_dir)

        # 3. Add Lakebase config to app.yaml
        self._add_lakebase_env_vars(output_dir)

        # 4. Update requirements.txt
        self._add_memory_dependencies(output_dir)

        print("âœ… Memory integration complete")

    def _copy_memory_manager(self, output_dir: Path) -> None:
        """Copy memory_manager.py to the output directory."""
        # Get memory_manager template
        template_path = Path(__file__).parent / "templates" / "assistant" / "memory_manager.py.jinja2"
        
        if not template_path.exists():
            raise FileNotFoundError(f"Memory manager template not found: {template_path}")
        
        # Copy as memory_manager.py (remove .jinja2 extension for now)
        dest_path = output_dir / "memory_manager.py"
        shutil.copy(template_path, dest_path)
        print("âœ… Added memory_manager.py")

    def _inject_memory_into_streamlit(self, output_dir: Path) -> None:
        """Inject MemoryManager into Streamlit app.py."""
        app_py_path = output_dir / "app.py"
        if not app_py_path.exists():
            print("âš ï¸  app.py not found, skipping memory injection")
            return
        
        content = app_py_path.read_text()
        
        # Add memory_manager import
        import_block = """from memory_manager import MemoryManager, generate_session_id
"""
        
        if "from memory_manager import" not in content:
            # Add after existing imports
            content = content.replace(
                "from collections import OrderedDict",
                f"from collections import OrderedDict\n{import_block}"
            )
        
        # Initialize MemoryManager after SERVING_ENDPOINT check
        memory_init = """
# Initialize Memory Manager for conversation persistence
try:
    memory_manager = MemoryManager()
    print("âœ… Memory initialized")
except Exception as e:
    print(f"âš ï¸  Memory initialization failed: {e}")
    print("   Falling back to in-memory history only")
    memory_manager = None
"""
        
        if "memory_manager = MemoryManager()" not in content:
            content = content.replace(
                "ENDPOINT_SUPPORTS_FEEDBACK = endpoint_supports_feedback(SERVING_ENDPOINT)",
                f"ENDPOINT_SUPPORTS_FEEDBACK = endpoint_supports_feedback(SERVING_ENDPOINT)\n{memory_init}"
            )
        
        # Update session state initialization to use persistent session_id
        session_init = """# --- Init state ---
if "session_id" not in st.session_state:
    st.session_state.session_id = generate_session_id()
    print(f"ðŸ” New session: {st.session_state.session_id}")

if "history" not in st.session_state:
    st.session_state.history = []

# Load persistent history from memory if available
if "history_loaded" not in st.session_state and memory_manager:
    try:
        # Load previous messages from database
        db_messages = memory_manager.get_history(st.session_state.session_id)
        if db_messages:
            print(f"ðŸ“œ Loaded {len(db_messages)} messages from memory")
            # Convert DB format to UI format
            for msg in db_messages:
                if msg["role"] == "user":
                    st.session_state.history.append(UserMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    st.session_state.history.append(AssistantResponse(
                        messages=[{"role": "assistant", "content": msg["content"]}],
                        request_id=None
                    ))
        st.session_state.history_loaded = True
    except Exception as e:
        print(f"âš ï¸  Could not load history: {e}")
        st.session_state.history_loaded = True
"""
        
        if "if \"history\" not in st.session_state:" in content:
            content = content.replace(
                """# --- Init state ---
if "history" not in st.session_state:
    st.session_state.history = []""",
                session_init
            )
        
        # Add memory persistence for user messages (inject after user_msg.render())
        user_store = """
    
    # Store user message in persistent memory
    if memory_manager:
        try:
            memory_manager.store_message(
                session_id=st.session_state.session_id,
                role="user",
                content=prompt
            )
            print(f"ðŸ’¾ Stored user message (session: {st.session_state.session_id})")
        except Exception as e:
            print(f"âš ï¸  Could not store user message: {e}")"""
        
        if "user_msg.render(" in content and "# Store user message" not in content:
            content = content.replace(
                "user_msg.render(len(st.session_state.history) - 1)",
                f"user_msg.render(len(st.session_state.history) - 1){user_store}"
            )
        
        # Add memory persistence for assistant messages (inject after append(assistant_response))
        assistant_store = """
    
    # Store assistant response in persistent memory
    if memory_manager and assistant_response.messages:
        try:
            # Extract text content from assistant response
            assistant_content = ""
            for msg in assistant_response.messages:
                if isinstance(msg, dict) and msg.get("role") == "assistant":
                    assistant_content += msg.get("content", "")
            
            if assistant_content:
                memory_manager.store_message(
                    session_id=st.session_state.session_id,
                    role="assistant",
                    content=assistant_content
                )
                print(f"ðŸ’¾ Stored assistant message (session: {st.session_state.session_id})")
        except Exception as e:
            print(f"âš ï¸  Could not store assistant message: {e}")"""
        
        if "st.session_state.history.append(assistant_response)" in content and "# Store assistant response" not in content:
            content = content.replace(
                "st.session_state.history.append(assistant_response)",
                f"st.session_state.history.append(assistant_response){assistant_store}"
            )
        
        app_py_path.write_text(content)
        print("âœ… Injected memory into app.py")

    def _add_lakebase_env_vars(self, output_dir: Path) -> None:
        """Add Lakebase environment variables to app.yaml."""
        app_yaml_path = output_dir / "app.yaml"
        if not app_yaml_path.exists():
            print("âš ï¸  app.yaml not found, skipping Lakebase config")
            return
        
        content = app_yaml_path.read_text()
        
        # Add Lakebase env vars
        lakebase_env = """  - name: "LAKEBASE_HOST"
    value: "your-lakebase-host.cloud.databricks.com"  # Update with your Lakebase host
  - name: "LAKEBASE_DATABASE"
    value: "agents"  # Update with your database name
  - name: "LAKEBASE_USER"
    value: "your_user"  # Update with your username
  - name: "LAKEBASE_PASSWORD"
    value: "your_password"  # Update with your password (or use secrets)
  - name: "PGSSLMODE"
    value: "require"
  - name: "PGCHANNELBINDING"
    value: "prefer"
"""
        
        # Add after SERVING_ENDPOINT
        if "LAKEBASE_HOST" not in content:
            content = content.replace(
                'value: "databricks-claude-sonnet-4"',
                f'value: "databricks-claude-sonnet-4"\n{lakebase_env}'
            )
            app_yaml_path.write_text(content)
            print("âœ… Added Lakebase configuration to app.yaml")
            print("âš ï¸  Update app.yaml with your Lakebase credentials")

    def _add_memory_dependencies(self, output_dir: Path) -> None:
        """Add memory dependencies to requirements.txt."""
        req_path = output_dir / "requirements.txt"
        if not req_path.exists():
            print("âš ï¸  requirements.txt not found")
            return
        
        content = req_path.read_text()
        
        if "psycopg2-binary" not in content:
            content += "\n# Memory dependencies\npsycopg2-binary>=2.9.9\n"
            req_path.write_text(content)
            print("âœ… Added psycopg2-binary to requirements.txt")

    def integrate_rag(self, output_dir: Path, rag_config: Dict[str, Any]) -> None:
        """Add RAG capabilities to the template (for L2+)."""
        # TODO: Inject RAG manager into the app
        print("âš ï¸  RAG integration not yet implemented for Databricks templates")
        print("   Will be added in future update")


def generate_with_databricks_template(name: str, level: str, options: Dict[str, Any], output_dir: str) -> Path:
    """
    Generate an agent app using official Databricks templates.

    Args:
        name: App name
        level: Agent level (chatbot, assistant, etc.)
        options: Generation options (model, ui, streaming, etc.)
        output_dir: Output directory path

    Returns:
        Path to generated app
    """
    integrator = DatabricksTemplateIntegrator()
    ui = options.get("ui", "streamlit")
    output_path = Path(output_dir)

    # Copy the official template
    integrator.copy_template(ui, output_path)

    # Add level to options for customization
    options_with_level = {**options, "level": level}

    # Customize with user options
    integrator.customize_template(output_path, options_with_level)

    # Add memory if L2+
    if level == "assistant":
        memory_config = {"ui": ui}
        integrator.integrate_memory(output_path, memory_config)

    # Add RAG if enabled
    if options.get("enable_rag"):
        rag_config = {}  # TODO: Extract from options
        integrator.integrate_rag(output_path, rag_config)

    return output_path
